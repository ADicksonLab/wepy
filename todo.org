#+TODO: TODO | DONE CANCELLED
* Simulation manager architecture

** TODO [#B] allow for resampler to get information on the whole tree of data :feature:

* Walker class

** TODO [#A] API and specs for a gneral Walker class               :api:core:

There are some notes on this in my lab notebook

* Resampler Helper Module

** TODO [#A] API and specs for a general Resampler                      :api:

- distance metric
- novelty/decision function


** TODO [#A] Distance metric API and specs                              :api:

** TODO [#A] novelty/decision function API and specs                    :api:

** TODO [#B] rewrite WExplore2 and WExplore in general framework        :app:

* HDF5

** TODO [#A] get methods for warp, bc, resampling records              :core:

** TODO [#A] sparse atoms slices                                    :feature:

We want to have a dedicated group in a trajectory for alternative
representations of the positions of atoms in the trajectories.

This is because we want to be able to save only the positions we need
for analysis of a subset of atoms that are of interest most of the
time (i.e. just the protein and not the solvent) to save memory but
still be able to have restart values.

What does this require?
- separate topology
- separate group for alternate representations (field name: `alt_reps`)
- atom selections for both the main positions field and the alt_reps
  given to the Reporter
- methods for retrieving full systems properly
- methods for writing trajectories with either full system or main
  positions
- methods for writing restarts for appropriate MD engines



** TODO [#B] fix compute observable to write feature vector style      :core:

This isn't really something I can fix since it relies on the
observable function being correct.

Unless I changed that so that the observable function works on a
single frame and then is mapped onto the whole trajectory.

Maybe that is the wayt o go. Since it makes writing those functions
easier anyways.


hmm this would involve rewriting the `traj_fields_map` function which
is not trivial.

The way it is now I would need to have the mapping function understand
this.

Or I could wrap the passed in function in a wrapper that understands
that it is a trajectory fields dictionary it is working with and not a
single frame.

Ok well I was able to do this and I think I am remembering why I had
to do it this way which was that this method will work for a normal
map function, except you can't do this and pickle the objects which is
needed for using something like scoop which uses a message queue.

Okay demoting this but the branch will still exist.

** TODO [#B] restarting simulations, multiple runs                     :core:



** TODO [#B] check file is correct

I noticed that constructing a WepyHDF5 object from a TrajHDF5 file
there is no complaint. There should be.

** TODO [#B] allow for passing in of real np.dtypes to resampling records :core:api:

special handling for the variable length "tokens"

** TODO [#B] add records for the boundary conditions               :core:api:
This needs to be implemented in the WepyHDF5 and in the actual
boundary conditions class.

** TODO [#B] implement SWMR                                         :feature:





** TODO [#B] concat function                                    :feature:api:

I want to have a concat function similar to other major libraries that
puts runs from different simulations together. The specifications I
want it to have are:

- options for inplace and copying
  - inplace on a 'master' file object, probably the first in the list passed.
  - another option (True by default) which deletes the members of the
    concat after a successful concatenation
  - make a copy of the new file and leave all the others untouched

** TODO [#B] full slice across datasets in TrajHDF5             :feature:api:

get all values for a collection of indices, with fancy slicing

Call it a cycle cross section.

Should be a function for each field of a run to get the cycle data:
- cycle_resampling(run_idx, cycle_idxs)
- cycle_boundary_conditions(run_idx, cycle_idxs)
- cycle_warping(run_idx, cycle_idxs)
- cycle_trajectories(run_idx, cycle_idxs)
- cycle_cross_section(run_idx, cycle_idxs, fields=['trajectories', 'resampling',
                                                   'boundary_conditions', 'warping'])
  - which calls the other functions based on what they are.


Nazanin was supposed to be working on this.

** TODO [#B] implement run cycle slice                  :feature:api:nazanin:

** TODO [#B] original WExplore algorithm                :feature:application:
** TODO [#B] implement run cycle map function           :feature:nazanin:api:

** TODO [#B] implement run cycle compute observables    :feature:nazanin:api:
** TODO [#C] HDF5 topology                                    :core:topology:

** TODO [#C] save weights on export_traj to TrajHDF5                :feature:

Save them in the observables.

Do we save them automatically?
as an option?
- [X] Or must be done manually?

** TODO [#C] Virtual Datasets (VDS) for adding observables          :feature:
** TODO [#C] implement chunking strategies                      :feature:api:

- [ ] protein, ligand, solvent
- [ ] ligand, binding-site

** TODO [#C] compliance infrastructure                          :feature:api:

** TODO [#C] only accept Quantity type objects that match/convert units :feature:api:

This will require choosing a unit library:
- simtk.units
- pint

** TODO [#C] simulation reproducibility metadata                :feature:api:

** TODO [#C] traj object for trajs in WepyHDF5                  :feature:api:

This would have the same API as the TrajHDF5 object.

** TODO [#C] add support for trajectory total ordering          :feature:api:

That means a single unique positive integer index for every trajectory in the whole file.

Support this as an trajectory selector in the iter_trajs.


** TODO [#C] save only complement for sparse atom slices            :feature:

Instead of saving the entire system of atoms for sparse full systems
you could just save the complement to the main positions field.

** TODO [#C] use h5py variable length datasets instead of my solution :feature:backend:

Didn't know this was a feature of h5py and am curious to see how this
is implemented underneath and whether it is an hdf5 standard thing.

H5py is not the only library we want to be read this data from.

** TODO [#C] use h5py enumeration type instead of my solution :feature:backend:



** CANCELLED [#B] allow for arbitrary number of frames to be saved in HDF5 traj part :core:


